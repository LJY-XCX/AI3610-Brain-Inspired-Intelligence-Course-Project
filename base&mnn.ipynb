{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7ebd6503",
      "metadata": {
        "id": "7ebd6503"
      },
      "source": [
        "# 大作业要求"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f49c1bc6",
      "metadata": {
        "id": "f49c1bc6"
      },
      "source": [
        "1.大作业以2-3人为一组完成，提交材料包括PPT（最后一次课展示成果）+ 可运行的jupyter notebook，标注相应的注释并给出运行结果 + 最终的大作业报告（正文不超过5页word/pdf，附录可选不限，需组内各成员单独提交，内容为本人在课程大作业中的贡献以及对大作业问题的思考) + 提交包含分工情况及组内各成员工作量占比的表格。分工表格需组内所有成员签字确认；\n",
        "\n",
        "2.禁止抄袭，发现雷同，所有雷同提交分数除以2；\n",
        "\n",
        "3.写清楚大作业中的贡献和创新点，若使用开源代码和论文中的方法，在报告中必须注明（不可作为本人创新点），发现不标注引用，分数除以2。\n",
        "\n",
        "最后一次课展示说明： 1.样例 PPT例子：https://www.sohu.com/a/166633625_642762 2.展示时间限制：展示时间为6分钟讲+2分钟同学助教老师自由提问\n",
        "\n",
        "大作业报告：强调个人对问题的理解，以及贡献，建议增加在提问反馈之后的改进结果。\n",
        "\n",
        "最终评分为:30%展示评分+70%大作业报告"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95c69ae0",
      "metadata": {
        "id": "95c69ae0"
      },
      "source": [
        "# 问题描述"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a06c540",
      "metadata": {
        "id": "2a06c540"
      },
      "source": [
        "深度神经网络通常采用独立同分布(Independent-Identically)的假设进行训练，即假设测试数据分布与训练数据分布相似。然而，当用于实际任务时，这一假设并不成立，导致其性能显著下降。虽然这种性能下降对于产品推荐等宽容性大的应用是可以接受的，但在医学等宽容性小的领域使用此类系统是危险的，因为它们可能导致严重事故。理想的人工智能系统应尽可能在分布外（Out-of-Distribution）的情况下有较强的分部外泛化能力。而提高分布外泛化的关键点，就是如何让模型学习到数据中的causal feature。\n",
        "\n",
        "一个简单的例子：以猫狗二分类为例，如果训练集中所有狗都在草地上，所有的猫都在沙发上，而测试集中所有的狗在沙发上，所有的猫在草地上，那么模型在没有测试集信息的情况下，很有可能根据训练集的信息把草地和狗联系在了一起，沙发和猫联系在了一起，当模型在测试集上测试时将会把在沙发上的狗误认为是猫。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36a63b0f",
      "metadata": {
        "id": "36a63b0f"
      },
      "source": [
        "# 数据集(Colored MNIST)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b15fcfe",
      "metadata": {
        "id": "5b15fcfe"
      },
      "source": [
        "Colored MNIST是MNIST手写数字分类数据集的变体，包含有三个不同的域，每个域包含一组不相交的红色或绿色数字并分别保存为train1.pt, train2.pt, test.pt。该数据集总共包含60000个样本。 \n",
        "\n",
        "在该数据集中，训练集和测试集之间存在Out-of-Distribution情况，color feature和数字产生了spurious correlation，即虚假的因果关系。从直观上来说，数字的形状为causal feature，数字的颜色为non-causal feature。\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e435fec6",
      "metadata": {
        "id": "e435fec6"
      },
      "source": [
        "# Colored MNIST数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "8a0bc19f",
      "metadata": {
        "id": "8a0bc19f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import grad\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import torchvision.datasets.utils as dataset_utils\n",
        "\n",
        "\n",
        "def color_grayscale_arr(arr, red=True):\n",
        "    \"\"\"Converts grayscale image to either red or green\"\"\"\n",
        "    assert arr.ndim == 2\n",
        "    dtype = arr.dtype\n",
        "    h, w = arr.shape\n",
        "    arr = np.reshape(arr, [h, w, 1])\n",
        "    if red:\n",
        "        arr = np.concatenate([arr,\n",
        "                              np.zeros((h, w, 2), dtype=dtype)], axis=2)\n",
        "    else:\n",
        "        arr = np.concatenate([np.zeros((h, w, 1), dtype=dtype),\n",
        "                              arr,\n",
        "                              np.zeros((h, w, 1), dtype=dtype)], axis=2)\n",
        "    return arr\n",
        "\n",
        "\n",
        "class coloredMNIST(datasets.VisionDataset):\n",
        "    \"\"\"\n",
        "  Colored MNIST dataset for testing IRM. Prepared using procedure from https://arxiv.org/pdf/1907.02893.pdf\n",
        "\n",
        "  Args:\n",
        "    root (string): Root directory of dataset where ``ColoredMNIST/*.pt`` will exist.\n",
        "    env (string): Which environment to load. Must be 1 of 'train1', 'train2', 'test', or 'all_train'.\n",
        "    transform (callable, optional): A function/transform that  takes in an PIL image\n",
        "      and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
        "    target_transform (callable, optional): A function/transform that takes in the\n",
        "      target and transforms it.\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, root='./data', env='test', transform=None, target_transform=None):\n",
        "        super(coloredMNIST, self).__init__(root, transform=transform,\n",
        "                                           target_transform=target_transform)\n",
        "\n",
        "        self.prepare_colored_mnist()\n",
        "        if env in ['train1', 'train2', 'test']:\n",
        "            self.data_label_tuples = torch.load(os.path.join(self.root, 'ColoredMNIST', env) + '.pt')\n",
        "        elif env == 'all_train':\n",
        "            self.data_label_tuples = torch.load(os.path.join(self.root, 'ColoredMNIST', 'train1.pt')) + \\\n",
        "                                     torch.load(os.path.join(self.root, 'ColoredMNIST', 'train2.pt'))\n",
        "        else:\n",
        "            raise RuntimeError(f'{env} env unknown. Valid envs are train1, train2, test, and all_train')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "    Args:\n",
        "        index (int): Index\n",
        "\n",
        "    Returns:\n",
        "        tuple: (image, target) where target is index of the target class.\n",
        "    \"\"\"\n",
        "        img, target, color = self.data_label_tuples[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target, color\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_label_tuples)\n",
        "\n",
        "    def prepare_colored_mnist(self):\n",
        "        colored_mnist_dir = os.path.join(self.root, 'ColoredMNIST')\n",
        "        if os.path.exists(os.path.join(colored_mnist_dir, 'train1.pt')) \\\n",
        "                and os.path.exists(os.path.join(colored_mnist_dir, 'train2.pt')) \\\n",
        "                and os.path.exists(os.path.join(colored_mnist_dir, 'test.pt')):\n",
        "            print('Colored MNIST dataset already exists')\n",
        "            return\n",
        "\n",
        "        print('Preparing Colored MNIST')\n",
        "        train_mnist = datasets.mnist.MNIST(self.root, train=True, download=True)\n",
        "\n",
        "        train1_set = []\n",
        "        train2_set = []\n",
        "        test_set = []\n",
        "        for idx, (im, label) in enumerate(train_mnist):\n",
        "            if idx % 10000 == 0:\n",
        "                print(f'Converting image {idx}/{len(train_mnist)}')\n",
        "            im_array = np.array(im)\n",
        "\n",
        "            # Assign a binary label y to the image based on the digit\n",
        "            binary_label = 0 if label < 5 else 1\n",
        "\n",
        "            # Flip label with 25% probability\n",
        "            if np.random.uniform() < 0.25:\n",
        "                binary_label = binary_label ^ 1\n",
        "\n",
        "            # Color the image either red or green according to its possibly flipped label\n",
        "            color_red = binary_label == 0\n",
        "\n",
        "            # Flip the color with a probability e that depends on the environment\n",
        "            if idx < 20000:\n",
        "                # 20% in the first training environment\n",
        "                if np.random.uniform() < 0.2:\n",
        "                    color_red = not color_red\n",
        "            elif idx < 40000:\n",
        "                # 10% in the first training environment\n",
        "                if np.random.uniform() < 0.1:\n",
        "                    color_red = not color_red\n",
        "            else:\n",
        "                # 90% in the test environment\n",
        "                if np.random.uniform() < 0.9:\n",
        "                    color_red = not color_red\n",
        "\n",
        "            colored_arr = color_grayscale_arr(im_array, red=color_red)\n",
        "\n",
        "            # 数据中储存样本颜色\n",
        "            if idx < 20000:\n",
        "                train1_set.append((Image.fromarray(colored_arr), binary_label, color_red))\n",
        "            elif idx < 40000:\n",
        "                train2_set.append((Image.fromarray(colored_arr), binary_label, color_red))\n",
        "            else:\n",
        "                test_set.append((Image.fromarray(colored_arr), binary_label, color_red))\n",
        "\n",
        "            # Debug\n",
        "            # print('original label', type(label), label)\n",
        "            # print('binary label', binary_label)\n",
        "            # print('assigned color', 'red' if color_red else 'green')\n",
        "            # plt.imshow(colored_arr)\n",
        "            # plt.show()\n",
        "            # break\n",
        "\n",
        "        #dataset_utils.makedir_exist_ok(colored_mnist_dir)\n",
        "        torch.save(train1_set, os.path.join(colored_mnist_dir, 'train1.pt'))\n",
        "        torch.save(train2_set, os.path.join(colored_mnist_dir, 'train2.pt'))\n",
        "        torch.save(test_set, os.path.join(colored_mnist_dir, 'test.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "2ea28660",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ea28660",
        "outputId": "30c5f071-9eb0-403d-f85b-07d8096148ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colored MNIST dataset already exists\n",
            "0 False\n"
          ]
        }
      ],
      "source": [
        "# 第一次运行时需手动创建data/ColoredMNIST文件夹\n",
        "D = coloredMNIST(env='test')\n",
        "img, target, color = D[5]\n",
        "img.show()\n",
        "print(target, color)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11dfed0e",
      "metadata": {
        "id": "11dfed0e"
      },
      "source": [
        "# ▶︎▶︎▶︎基础部分"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94a20aac",
      "metadata": {
        "id": "94a20aac"
      },
      "source": [
        "### 1. 设计ColoredMNIST数据二分类的因果图，合理即可。并基于后门准则，推导𝑃(𝑦|𝑑𝑜(𝑥)) 【提示：因果图可以为E->X, E->Y, X->Y, E为环境，比如颜色】"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56f9f8b4",
      "metadata": {
        "id": "56f9f8b4"
      },
      "source": [
        "$P(y|do(x)) = \\Sigma_{e} P(y|x,e)P(x)$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be422f22",
      "metadata": {
        "id": "be422f22"
      },
      "source": [
        "### 2. 在ColoredMNIST数据上实现基于后门准则的因果推理算法，训练神经网络，提升模型预测准确度。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21c69d37",
      "metadata": {
        "id": "21c69d37"
      },
      "source": [
        "# 1. 读取数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "35f83e59",
      "metadata": {
        "id": "35f83e59"
      },
      "outputs": [],
      "source": [
        "########################################▶︎###############################\n",
        "###一下是一个简单的读取Colored MNIST例子，请进一步完善。可以进行数据预处理等操作。###\n",
        "#######################################################################\n",
        "\n",
        "class ColoredMNIST(datasets.VisionDataset):    \n",
        "    def __init__(self, path):\n",
        "        self.data_label = torch.load(path)\n",
        "        self.red_pics = []\n",
        "        self.green_pics = []\n",
        "        for img, target, color in self.data_label:\n",
        "            if (color):\n",
        "                self.red_pics.append((img, target))\n",
        "            else:\n",
        "                self.green_pics.append((img, target))\n",
        "        \n",
        "        # 把样本中的红色样本数补至相同\n",
        "        cnt = np.zeros(2)\n",
        "        for img, target in self.red_pics:\n",
        "            cnt[target] += 1\n",
        "        if (cnt[0]>cnt[1]):\n",
        "            for img, target in self.red_pics:\n",
        "                if (target==1):\n",
        "                    self.red_pics.append((img, target))\n",
        "                    cnt[1] += 1\n",
        "                    if (cnt[0] == cnt[1]):\n",
        "                        break\n",
        "        if (cnt[0]<cnt[1]):\n",
        "            for img, target in self.red_pics:\n",
        "                if (target==0):\n",
        "                    self.red_pics.append((img, target))\n",
        "                    cnt[0] += 1\n",
        "                    if (cnt[0] == cnt[1]):\n",
        "                        break    \n",
        "        \n",
        "        # 把样本中的绿色样本数补至相同\n",
        "        cnt = np.zeros(2)\n",
        "        for img, target in self.green_pics:\n",
        "            cnt[target] += 1\n",
        "        if (cnt[0]>cnt[1]):\n",
        "            for img, target in self.green_pics:\n",
        "                if (target==1):\n",
        "                    self.green_pics.append((img, target))\n",
        "                    cnt[1] += 1\n",
        "                    if (cnt[0] == cnt[1]):\n",
        "                        break\n",
        "        if (cnt[0]<cnt[1]):\n",
        "            for img, target in self.green_pics:\n",
        "                if (target==0):\n",
        "                    self.green_pics.append((img, target))\n",
        "                    cnt[0] += 1\n",
        "                    if (cnt[0] == cnt[1]):\n",
        "                        break\n",
        "        \n",
        "        # 把PIL_image转化为tensor，以使用dataloader来加载数据\n",
        "        trans = transforms.ToTensor()\n",
        "        self.data = []\n",
        "        for idx, (img, target) in enumerate(self.red_pics):\n",
        "            img_tensor = trans(img) * 255\n",
        "            self.data.append((img_tensor, target))\n",
        "        for idx, (img, target) in enumerate(self.green_pics):\n",
        "            img_tensor = trans(img) * 255\n",
        "            self.data.append((img_tensor, target))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index]\n",
        "        return img, target\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "e057cbed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e057cbed",
        "outputId": "cf13d7f3-f1cd-47c4-e68a-fe512b981f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1001\n",
            "1123\n"
          ]
        }
      ],
      "source": [
        "train_data = ColoredMNIST('data/ColoredMNIST/train1.pt')\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_data = ColoredMNIST('data/ColoredMNIST/test.pt')\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)\n",
        "print(len(train_loader))\n",
        "print(len(test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3abdfcd9",
      "metadata": {
        "id": "3abdfcd9"
      },
      "source": [
        "# 2. 定义模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "7427d5ed",
      "metadata": {
        "id": "7427d5ed"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64*4*4, 64)\n",
        "        self.fc2 = nn.Linear(64, 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 64*4*4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66eed82a",
      "metadata": {
        "id": "66eed82a"
      },
      "source": [
        "# 3. 训练模型并输出测试结果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "7682feff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7682feff",
        "outputId": "0833ab0c-7ac4-4850-90a5-f27d52adc109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6709)\n",
            "tensor(0.6915)\n",
            "tensor(0.6851)\n",
            "tensor(0.6881)\n",
            "tensor(0.6646)\n",
            "tensor(0.6767)\n",
            "tensor(0.6042)\n",
            "tensor(0.6428)\n",
            "tensor(0.6152)\n",
            "tensor(0.5951)\n"
          ]
        }
      ],
      "source": [
        "net = MyModel()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
        "\n",
        "def train_test_MyModel():\n",
        "    for epoch in range(10):\n",
        "        for idx, (img, target) in enumerate(train_loader):\n",
        "            #img += torch.normal(mean=0, std=10, size=img.shape)\n",
        "            optimizer.zero_grad()\n",
        "            output = net(img)\n",
        "            loss = loss_fn(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        correct = total = 0\n",
        "        for idx, (img, target) in enumerate(test_loader):\n",
        "            output = net(img)\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            correct += torch.sum(pred == target)\n",
        "            total += img.shape[0]\n",
        "        print(correct / total)\n",
        "\n",
        "train_test_MyModel()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0730aac3",
      "metadata": {
        "id": "0730aac3"
      },
      "source": [
        "# ▶︎▶︎▶︎提高部分"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1fab09f",
      "metadata": {
        "id": "d1fab09f"
      },
      "source": [
        "### 2. 将上述过程中用到的神经网络替换为Memristor，可使用MemTorch库，并研究方法提高其泛化性能；"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "2A70E39NrN20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A70E39NrN20",
        "outputId": "299b4099-a15e-463c-cc23-0fcd09d14a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: memtorch in /usr/local/lib/python3.8/dist-packages (1.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from memtorch) (1.21.6)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (from memtorch) (0.0.post1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from memtorch) (0.11.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from memtorch) (7.9.0)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from memtorch) (1.13.0+cu116)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from memtorch) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from memtorch) (1.7.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from memtorch) (0.14.0+cu116)\n",
            "Requirement already satisfied: lmfit in /usr/local/lib/python3.8/dist-packages (from memtorch) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from memtorch) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.2.0->memtorch) (4.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->memtorch) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->memtorch) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->memtorch) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->memtorch) (5.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->memtorch) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->memtorch) (57.4.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->memtorch) (0.18.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->memtorch) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->memtorch) (0.7.5)\n",
            "Requirement already satisfied: asteval>=0.9.28 in /usr/local/lib/python3.8/dist-packages (from lmfit->memtorch) (0.9.28)\n",
            "Requirement already satisfied: uncertainties>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from lmfit->memtorch) (3.1.7)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->memtorch) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->memtorch) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->memtorch) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->memtorch) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->memtorch) (2022.7)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->memtorch) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision->memtorch) (2.25.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->memtorch) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->memtorch) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->memtorch) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from uncertainties>=3.1.4->lmfit->memtorch) (0.16.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->memtorch) (0.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->memtorch) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->memtorch) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->memtorch) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->memtorch) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "%pip install memtorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "ee4dc522",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee4dc522",
        "outputId": "b96d1d1a-08a4-4b6d-8295-41de4f373a41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patched Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1)) -> bh.Conv2d(in_channels=3, out_channels=32, kernel_size=(5, 5), stride=(1, 1), padding=(0, 0))\n",
            "Patched Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1)) -> bh.Conv2d(in_channels=32, out_channels=64, kernel_size=(5, 5), stride=(1, 1), padding=(0, 0))\n",
            "Patched Linear(in_features=1024, out_features=64, bias=True) -> bh.Linear(in_features=1024, out_features=64, bias=True)\n",
            "Patched Linear(in_features=64, out_features=2, bias=True) -> bh.Linear(in_features=64, out_features=2, bias=True)\n",
            "Tuned bh.Conv2d(in_channels=3, out_channels=32, kernel_size=(5, 5), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.993118 [6651.863281, -0.001044]\n",
            "Tuned bh.Conv2d(in_channels=32, out_channels=64, kernel_size=(5, 5), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.997598 [2412.404785, -0.001807]\n",
            "Tuned bh.Linear(in_features=1024, out_features=64, bias=True). Coefficient of determination: 0.999190 [2591.459961, -0.001109]\n",
            "Tuned bh.Linear(in_features=64, out_features=2, bias=True). Coefficient of determination: 0.828139 [9406.141602, -0.079612]\n"
          ]
        }
      ],
      "source": [
        "import memtorch\n",
        "reference_memristor = memtorch.bh.memristor.VTEAM\n",
        "reference_memristor_params = {'time_series_resolution': 1e-10}\n",
        "memristor = reference_memristor(**reference_memristor_params)\n",
        "#memristor.plot_hysteresis_loop()\n",
        "#memristor.plot_bipolar_switching_behaviour()\n",
        "\n",
        "import copy\n",
        "from memtorch.mn.Module import patch_model\n",
        "from memtorch.map.Input import naive_scale\n",
        "from memtorch.map.Parameter import naive_map\n",
        "from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
        "\n",
        "r_on = 1.4e4\n",
        "r_off = 5e7\n",
        "\n",
        "\n",
        "def ANN_to_MNN(model, r_on, r_off, tile_shape, ADC_resolution, failure_percentage):\n",
        "    '''\n",
        "    model : pretrained model.\n",
        "    r_on : float\n",
        "        On (minimum) resistance of the device (ohms).\n",
        "    r_off : float\n",
        "        Off (maximum) resistance of the device (ohms).\n",
        "    tile_shape : int, int\n",
        "        Tile shape to use to store weights.\n",
        "    ADC_resolution : int\n",
        "        ADC resolution (bit width). If None, quantization noise is not accounted for.\n",
        "    lrs_proportion : float\n",
        "        Proportion of devices which become stuck at a low resistance state.\n",
        "    '''\n",
        "    model_ = copy.deepcopy(model)\n",
        "    reference_memristor = memtorch.bh.memristor.VTEAM\n",
        "    reference_memristor_params = {'time_series_resolution': 1e-10, 'r_off': r_off, 'r_on': r_on}\n",
        "\n",
        "    # 模型中每一层转化为忆阻器元件\n",
        "    patched_model = patch_model(copy.deepcopy(model_),\n",
        "                              memristor_model=reference_memristor,\n",
        "                              memristor_model_params=reference_memristor_params,\n",
        "                              module_parameters_to_patch=[torch.nn.Linear, torch.nn.Conv2d],\n",
        "                              mapping_routine=naive_map,\n",
        "                              transistor=True,\n",
        "                              programming_routine=None,\n",
        "                              scheme=memtorch.bh.Scheme.DoubleColumn,\n",
        "                              tile_shape=tile_shape,\n",
        "                              max_input_voltage=0.3,\n",
        "                              ADC_resolution=int(ADC_resolution),\n",
        "                              ADC_overflow_rate=0.,\n",
        "                              quant_method='linear')\n",
        "\n",
        "    # 加入非理想修正\n",
        "    patched_model = apply_nonidealities(patched_model,\n",
        "                                        non_idealities=[memtorch.bh.nonideality.NonIdeality.DeviceFaults],\n",
        "                                        lrs_proportion=failure_percentage,\n",
        "                                        hrs_proportion=0.,\n",
        "                                        electroform_proportion=0.)\n",
        "    \n",
        "    patched_model.tune_()\n",
        "\n",
        "    return patched_model\n",
        "\n",
        "MNN = ANN_to_MNN(net, r_on=r_on, r_off=r_off, tile_shape=(128,128), ADC_resolution=8, failure_percentage=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "CRfZg9ZWvxJv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRfZg9ZWvxJv",
        "outputId": "8b16febf-0dbe-499a-cc32-129e8c701033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5093)\n"
          ]
        }
      ],
      "source": [
        "# 测试检验MNN\n",
        "def test_MNN():\n",
        "    optimizer = optim.SGD(MNN.parameters(), lr=0.001)\n",
        "\n",
        "    correct = total = 0\n",
        "    for idx, (img, target) in enumerate(test_loader):\n",
        "        #print(torch.sum(torch.abs(img[0]-img[1])))\n",
        "        output = MNN(img)\n",
        "        pred = torch.argmax(output, dim=1)\n",
        "        correct += torch.sum(pred.cpu() == target)\n",
        "        total += img.shape[0]\n",
        "    print(correct / total)\n",
        "\n",
        "test_MNN()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "ox",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10 | packaged by conda-forge | (default, May 11 2021, 06:25:23) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "9bf23f2c9428cb096e9940666b5b07c0f044b949e3805dd171aa3e94f0771d01"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
